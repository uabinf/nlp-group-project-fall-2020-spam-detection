{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in c:\\users\\liqi9\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.42.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chardet\n",
    "with open('ICDM_REVIEWS_TO_RELEASE_encoding=utf-8.csv', 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(100000))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chinese(file):\n",
    "    pattern = re.compile(r'[^\\u4e00-\\u9fa5]')\n",
    "    chinese_txt = re.sub(pattern,'',file)\n",
    "    return chinese_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'review_id,label,user,ip,star,text\\nREVIEW0,+,USER1,IP1,5,他家的面很有嚼劲，牛肉汤很有味道，服务员的服务也特别的好，其中服务员顾存芳的服务特好！好喜欢她给我们服务！！！！\\nREVIEW1,-,USER2,IP2,4,鲜榨果汁很不错，水果都是很新鲜的，口感也很好，是个小妹妹态度非常好，环境也很好，但是专家告诉我们还是吃水果比较好  嘿嘿\\nREVIEW2,+,USER3,IP3,5,跟老婆过二人世界，就定了他家的一间包房，他家挺好的，跟老婆点了几个菜，边吃边聊，包房的话，那个小姑娘看我们两人也没怎么打扰，着让我感到挺舒服的\\nREVIEW3,-,USER4,IP4,5,我是在开业那天去得，他们的环境很好，进去给人一种很温软的感觉  他们的服务很好，销售很耐心的跟我和我老公介绍了各种口味  爆米花价格性价比很高，口味很多。  总得来说他们的服务态度非常的好，价格又很实惠，建议喜欢的朋友可以沃尔玛买~\\nREVIEW4,-,USER5,IP5,4,好像说属于宁波菜系，东西还可以，只是上菜速度比较慢，好在服务还不错。还有赠送的餐前小吃，水果是餐前送的，这一点很科学，赞！\\nREVIEW5,+,USER6,IP6,3,今天过来看一下，顺便买了一些零食，好实惠，，，，，，，，，，，，，，，，，，，，，，，，，，，，，，，服务员很热情。\\nREVIEW6,-,USER7,IP7,5,2号线科技馆下来找了好久，离地铁还是蛮远的，不过面包真心赞啊！有机会真想把这儿的面包全买了。环境也不错，价格也没有很离谱啦！ 红酒芝士的芝士真是超级多，满满的+_+\\nR'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData = open(\"ICDM_REVIEWS_TO_RELEASE_encoding=utf-8.csv\",encoding='utf-8').read()\n",
    "\n",
    "# Print the raw data\n",
    "rawData[0:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       他家的面很有嚼劲，牛肉汤很有味道，服务员的服务也特别的好，其中服务员顾存芳的服务特好！好喜欢...\n",
      "1       鲜榨果汁很不错，水果都是很新鲜的，口感也很好，是个小妹妹态度非常好，环境也很好，但是专家告诉...\n",
      "2       跟老婆过二人世界，就定了他家的一间包房，他家挺好的，跟老婆点了几个菜，边吃边聊，包房的话，那...\n",
      "3       我是在开业那天去得，他们的环境很好，进去给人一种很温软的感觉  他们的服务很好，销售很耐心的...\n",
      "4       好像说属于宁波菜系，东西还可以，只是上菜速度比较慢，好在服务还不错。还有赠送的餐前小吃，水果...\n",
      "                              ...                        \n",
      "9760    之前一直在苏浙汇吃，看到这边新开了家丰收日就去尝了下，味道不错，价格也比较实惠，不是很贵，包...\n",
      "9761    我一直等着世界末日的到来，等到21号，钱用光了，什么都没有了，结果它没有来，TMD谁造的谣啊...\n",
      "9762         菜很好吃，尤其是剁椒鱼头，强烈推荐！！建议老板稍微扩大一下场地，位置太少！每次去都要等！\n",
      "9763                     公司楼下 最好吃的麻辣烫 老板是河南人 煮麻辣烫的小姑娘长得不错\n",
      "9764    经常去的鸭王，每天每桌还可以点两道特价菜。很实惠，菜的味道又好。我还经常给我周边的朋友介绍他...\n",
      "Name: text, Length: 9765, dtype: object\n",
      "-----------------------------------------------------------\n",
      "  tag                                               text\n",
      "0   +  他家的面很有嚼劲，牛肉汤很有味道，服务员的服务也特别的好，其中服务员顾存芳的服务特好！好喜欢...\n",
      "1   -  鲜榨果汁很不错，水果都是很新鲜的，口感也很好，是个小妹妹态度非常好，环境也很好，但是专家告诉...\n",
      "2   +  跟老婆过二人世界，就定了他家的一间包房，他家挺好的，跟老婆点了几个菜，边吃边聊，包房的话，那...\n",
      "3   -  我是在开业那天去得，他们的环境很好，进去给人一种很温软的感觉  他们的服务很好，销售很耐心的...\n",
      "4   -  好像说属于宁波菜系，东西还可以，只是上菜速度比较慢，好在服务还不错。还有赠送的餐前小吃，水果...\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('ICDM_REVIEWS_TO_RELEASE_encoding=utf-8.csv',encoding='utf-8', \n",
    "                   usecols=[1,5], names=['tag','text'], header=0)\n",
    "print(data['text'])\n",
    "print('-----------------------------------------------------------')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape: (9765, 2)\n",
      "type(data) <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print('data.shape:',data.shape)\n",
    "print('type(data)', type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       +\n",
      "1       -\n",
      "2       +\n",
      "3       -\n",
      "4       -\n",
      "       ..\n",
      "9760    +\n",
      "9761    -\n",
      "9762    +\n",
      "9763    -\n",
      "9764    +\n",
      "Name: tag, Length: 9765, dtype: object\n",
      "['+', '-', '+', '-', '-']\n",
      "['他家的面很有嚼劲，牛肉汤很有味道，服务员的服务也特别的好，其中服务员顾存芳的服务特好！好喜欢她给我们服务！！！！', '鲜榨果汁很不错，水果都是很新鲜的，口感也很好，是个小妹妹态度非常好，环境也很好，但是专家告诉我们还是吃水果比较好  嘿嘿', '跟老婆过二人世界，就定了他家的一间包房，他家挺好的，跟老婆点了几个菜，边吃边聊，包房的话，那个小姑娘看我们两人也没怎么打扰，着让我感到挺舒服的', '我是在开业那天去得，他们的环境很好，进去给人一种很温软的感觉  他们的服务很好，销售很耐心的跟我和我老公介绍了各种口味  爆米花价格性价比很高，口味很多。  总得来说他们的服务态度非常的好，价格又很实惠，建议喜欢的朋友可以沃尔玛买~', '好像说属于宁波菜系，东西还可以，只是上菜速度比较慢，好在服务还不错。还有赠送的餐前小吃，水果是餐前送的，这一点很科学，赞！']\n",
      "9765\n",
      "9765\n",
      "Input data has 9765 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "labelList = []\n",
    "textList = []\n",
    "print(data['tag'])\n",
    "for i in data['tag']:\n",
    "    labelList.append(i)\n",
    "for j in data['text']:\n",
    "    textList.append(j)\n",
    "\n",
    "print(labelList[0:5])\n",
    "print(textList[0:5])\n",
    "\n",
    "print(len(labelList))\n",
    "print(len(textList))\n",
    "print(\"Input data has {} rows and {} columns\".format(len(data), len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zhon in c:\\users\\liqi9\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (1.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install zhon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､　、〃〈〉《》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏﹑﹔·！？｡。\n"
     ]
    }
   ],
   "source": [
    "from zhon.hanzi import punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        他家的面很有嚼劲牛肉汤很有味道服务员的服务也特别的好其中服务员顾存芳的服务特好好喜欢她给我们服务\n",
      "1       鲜榨果汁很不错水果都是很新鲜的口感也很好是个小妹妹态度非常好环境也很好但是专家告诉我们还是吃...\n",
      "2       跟老婆过二人世界就定了他家的一间包房他家挺好的跟老婆点了几个菜边吃边聊包房的话那个小姑娘看我...\n",
      "3       我是在开业那天去得他们的环境很好进去给人一种很温软的感觉  他们的服务很好销售很耐心的跟我和...\n",
      "4       好像说属于宁波菜系东西还可以只是上菜速度比较慢好在服务还不错还有赠送的餐前小吃水果是餐前送的...\n",
      "                              ...                        \n",
      "9760    之前一直在苏浙汇吃看到这边新开了家丰收日就去尝了下味道不错价格也比较实惠不是很贵包房相对比较...\n",
      "9761    我一直等着世界末日的到来等到21号钱用光了什么都没有了结果它没有来TMD谁造的谣啊我就剩10...\n",
      "9762                菜很好吃尤其是剁椒鱼头强烈推荐建议老板稍微扩大一下场地位置太少每次去都要等\n",
      "9763                     公司楼下 最好吃的麻辣烫 老板是河南人 煮麻辣烫的小姑娘长得不错\n",
      "9764    经常去的鸭王每天每桌还可以点两道特价菜很实惠菜的味道又好我还经常给我周边的朋友介绍他们家呢这...\n",
      "Name: text_nopunct, Length: 9765, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    text_only = re.sub('[{}]+'.format(punctuation), \"\", text)\n",
    "    return text_only\n",
    "data['text_nopunct'] = data['text'].apply(lambda x: remove_punct(x))\n",
    "print(data['text_nopunct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\liqi9\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.596 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "      <th>text_nopunct</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>他家的面很有嚼劲，牛肉汤很有味道，服务员的服务也特别的好，其中服务员顾存芳的服务特好！好喜欢...</td>\n",
       "      <td>他家的面很有嚼劲牛肉汤很有味道服务员的服务也特别的好其中服务员顾存芳的服务特好好喜欢她给我们服务</td>\n",
       "      <td>[他家, 的, 面, 很, 有, 嚼, 劲, 牛肉汤, 很, 有, 味道, 服务员, 的, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>鲜榨果汁很不错，水果都是很新鲜的，口感也很好，是个小妹妹态度非常好，环境也很好，但是专家告诉...</td>\n",
       "      <td>鲜榨果汁很不错水果都是很新鲜的口感也很好是个小妹妹态度非常好环境也很好但是专家告诉我们还是吃...</td>\n",
       "      <td>[鲜榨, 果汁, 很, 不错, 水果, 都, 是, 很, 新鲜, 的, 口感, 也, 很, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>+</td>\n",
       "      <td>跟老婆过二人世界，就定了他家的一间包房，他家挺好的，跟老婆点了几个菜，边吃边聊，包房的话，那...</td>\n",
       "      <td>跟老婆过二人世界就定了他家的一间包房他家挺好的跟老婆点了几个菜边吃边聊包房的话那个小姑娘看我...</td>\n",
       "      <td>[跟, 老婆, 过, 二人, 世界, 就定, 了, 他家, 的, 一间, 包房, 他家, 挺...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>我是在开业那天去得，他们的环境很好，进去给人一种很温软的感觉  他们的服务很好，销售很耐心的...</td>\n",
       "      <td>我是在开业那天去得他们的环境很好进去给人一种很温软的感觉  他们的服务很好销售很耐心的跟我和...</td>\n",
       "      <td>[我, 是, 在, 开业, 那天, 去, 得, 他们, 的, 环境, 很, 好, 进去, 给...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>好像说属于宁波菜系，东西还可以，只是上菜速度比较慢，好在服务还不错。还有赠送的餐前小吃，水果...</td>\n",
       "      <td>好像说属于宁波菜系东西还可以只是上菜速度比较慢好在服务还不错还有赠送的餐前小吃水果是餐前送的...</td>\n",
       "      <td>[好像, 说, 属于, 宁波, 菜系, 东西, 还, 可以, 只是, 上菜, 速度, 比较慢...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tag                                               text  \\\n",
       "0   +  他家的面很有嚼劲，牛肉汤很有味道，服务员的服务也特别的好，其中服务员顾存芳的服务特好！好喜欢...   \n",
       "1   -  鲜榨果汁很不错，水果都是很新鲜的，口感也很好，是个小妹妹态度非常好，环境也很好，但是专家告诉...   \n",
       "2   +  跟老婆过二人世界，就定了他家的一间包房，他家挺好的，跟老婆点了几个菜，边吃边聊，包房的话，那...   \n",
       "3   -  我是在开业那天去得，他们的环境很好，进去给人一种很温软的感觉  他们的服务很好，销售很耐心的...   \n",
       "4   -  好像说属于宁波菜系，东西还可以，只是上菜速度比较慢，好在服务还不错。还有赠送的餐前小吃，水果...   \n",
       "\n",
       "                                        text_nopunct  \\\n",
       "0   他家的面很有嚼劲牛肉汤很有味道服务员的服务也特别的好其中服务员顾存芳的服务特好好喜欢她给我们服务   \n",
       "1  鲜榨果汁很不错水果都是很新鲜的口感也很好是个小妹妹态度非常好环境也很好但是专家告诉我们还是吃...   \n",
       "2  跟老婆过二人世界就定了他家的一间包房他家挺好的跟老婆点了几个菜边吃边聊包房的话那个小姑娘看我...   \n",
       "3  我是在开业那天去得他们的环境很好进去给人一种很温软的感觉  他们的服务很好销售很耐心的跟我和...   \n",
       "4  好像说属于宁波菜系东西还可以只是上菜速度比较慢好在服务还不错还有赠送的餐前小吃水果是餐前送的...   \n",
       "\n",
       "                                      text_tokenized  \n",
       "0  [他家, 的, 面, 很, 有, 嚼, 劲, 牛肉汤, 很, 有, 味道, 服务员, 的, ...  \n",
       "1  [鲜榨, 果汁, 很, 不错, 水果, 都, 是, 很, 新鲜, 的, 口感, 也, 很, ...  \n",
       "2  [跟, 老婆, 过, 二人, 世界, 就定, 了, 他家, 的, 一间, 包房, 他家, 挺...  \n",
       "3  [我, 是, 在, 开业, 那天, 去, 得, 他们, 的, 环境, 很, 好, 进去, 给...  \n",
       "4  [好像, 说, 属于, 宁波, 菜系, 东西, 还, 可以, 只是, 上菜, 速度, 比较慢...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    jieba_list = jieba.cut(text, cut_all=False)\n",
    "    tokens = ' '.join(jieba_list).split(' ')\n",
    "    return tokens\n",
    "data['text_tokenized'] = data['text_nopunct'].apply(lambda x:tokenize(x.lower()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一', '一.', '一一', '一下', '一个', '一些', '一何', '一切', '一则', '一则通过', '一天', '一定', '一方面', '一旦', '一时', '一来', '一样', '一次', '一片', '一番', '一直', '一致', '一般', '一起', '一转眼', '一边', '一面', '七', '万一', '三', '三天两头', '三番两次', '三番五次', '上', '上下', '上升', '上去', '上来', '上述', '上面', '下', '下列', '下去', '下来', '下面', '不', '不一', '不下', '不久', '不了', '不亦乐乎', '不仅', '不仅...而且', '不仅仅', '不仅仅是', '不会', '不但', '不但...而且', '不光', '不免', '不再', '不力', '不单', '不变', '不只', '不可', '不可开交', '不可抗拒', '不同', '不外', '不外乎', '不够', '不大', '不如', '不妨', '不定', '不对', '不少', '不尽', '不尽然', '不巧', '不已', '不常', '不得', '不得不', '不得了', '不得已', '不必', '不怎么', '不怕', '不惟', '不成', '不拘', '不择手段', '不敢', '不料', '不断', '不日', '不时', '不是', '不曾', '不止', '不止一次', '不比', '不消', '不满', '不然', '不然的话', '不特', '不独', '不由得', '不知不觉', '不管', '不管怎样', '不经意', '不胜', '不能', '不能不', '不至于', '不若', '不要', '不论', '不起', '不足', '不过', '不迭', '不问', '不限', '与', '与其', '与其说', '与否', '与此同时', '专门', '且', '且不说', '且说', '两者', '严格', '严重', '个', '个人', '个别', '中小', '中间', '丰富', '串行', '临', '临到', '为', '为主', '为了', '为什么', '为什麽', '为何', '为止', '为此', '为着', '主张', '主要', '举凡', '举行', '乃', '乃至', '乃至于', '么', '之', '之一', '之前', '之后', '之後', '之所以', '之类', '乌乎', '乎', '乒', '乘', '乘势', '乘机', '乘胜', '乘虚', '乘隙', '九', '也', '也好', '也就是说', '也是', '也罢', '了', '了解', '争取', '二', '二来', '二话不说', '二话没说', '于', '于是', '于是乎', '云云', '云尔', '互', '互相', '五', '些', '交口', '亦', '产生', '亲口', '亲手', '亲眼', '亲自', '亲身', '人', '人人', '人们', '人家', '人民', '什么', '什么样', '什麽', '仅', '仅仅', '今', '今后', '今天', '今年', '今後', '介于', '仍', '仍旧', '仍然', '从', '从不', '从严', '从中', '从事', '从今以后', '从优', '从古到今', '从古至今', '从头', '从宽', '从小', '从新', '从无到有', '从早到晚', '从未', '从来', '从此', '从此以后', '从而', '从轻', '从速', '从重', '他', '他人', '他们', '他是', '他的', '代替', '以', '以上', '以下', '以为', '以便', '以免', '以前', '以及', '以后', '以外', '以後', '以故', '以期', '以来', '以至', '以至于', '以致', '们', '任', '任何', '任凭', '任务', '企图', '伙同', '会', '伟大', '传', '传说', '传闻', '似乎', '似的', '但', '但凡', '但愿', '但是', '何', '何乐而不为', '何以', '何况', '何处', '何妨', '何尝', '何必', '何时', '何止', '何苦', '何须', '余外', '作为', '你', '你们', '你是', '你的', '使', '使得', '使用', '例如', '依', '依据', '依照', '依靠', '便', '便于', '促进', '保持', '保管', '保险', '俺', '俺们', '倍加', '倍感', '倒不如', '倒不如说', '倒是', '倘', '倘使', '倘或', '倘然', '倘若', '借', '借以', '借此', '假使', '假如', '假若', '偏偏', '做到', '偶尔', '偶而', '傥然', '像', '儿', '允许', '元／吨', '充其极', '充其量', '充分', '先不先', '先后', '先後', '先生', '光', '光是', '全体', '全力', '全年', '全然', '全身心', '全部', '全都', '全面', '八', '八成', '公然', '六', '兮', '共', '共同', '共总', '关于', '其', '其一', '其中', '其二', '其他', '其余', '其后', '其它', '其实', '其次', '具体', '具体地说', '具体来说', '具体说来', '具有', '兼之', '内', '再', '再其次', '再则', '再有', '再次', '再者', '再者说', '再说', '冒', '冲', '决不', '决定', '决非', '况且', '准备', '凑巧', '凝神', '几', '几乎', '几度', '几时', '几番', '几经', '凡', '凡是', '凭', '凭借', '出', '出于', '出去', '出来', '出现', '分别', '分头', '分期', '分期分批', '切', '切不可', '切切', '切勿', '切莫', '则', '则甚', '刚', '刚好', '刚巧', '刚才', '初', '别', '别人', '别处', '别是', '别的', '别管', '别说', '到', '到了儿', '到处', '到头', '到头来', '到底', '到目前为止', '前后', '前此', '前者', '前进', '前面', '加上', '加之', '加以', '加入', '加强', '动不动', '动辄', '勃然', '匆匆', '十分', '千', '千万', '千万千万', '半', '单', '单单', '单纯', '即', '即令', '即使', '即便', '即刻', '即如', '即将', '即或', '即是说', '即若', '却', '却不', '历', '原来', '去', '又', '又及', '及', '及其', '及时', '及至', '双方', '反之', '反之亦然', '反之则', '反倒', '反倒是', '反应', '反手', '反映', '反而', '反过来', '反过来说', '取得', '取道', '受到', '变成', '古来', '另', '另一个', '另一方面', '另外', '另悉', '另方面', '另行', '只', '只当', '只怕', '只是', '只有', '只消', '只要', '只限', '叫', '叫做', '召开', '叮咚', '叮当', '可', '可以', '可好', '可是', '可能', '可见', '各', '各个', '各人', '各位', '各地', '各式', '各种', '各级', '各自', '合理', '同', '同一', '同时', '同样', '后', '后来', '后者', '后面', '向', '向使', '向着', '吓', '吗', '否则', '吧', '吧哒', '吱', '呀', '呃', '呆呆地', '呐', '呕', '呗', '呜', '呜呼', '呢', '周围', '呵', '呵呵', '呸', '呼哧', '呼啦', '咋', '和', '咚', '咦', '咧', '咱', '咱们', '咳', '哇', '哈', '哈哈', '哉', '哎', '哎呀', '哎哟', '哗', '哗啦', '哟', '哦', '哩', '哪', '哪个', '哪些', '哪儿', '哪天', '哪年', '哪怕', '哪样', '哪边', '哪里', '哼', '哼唷', '唉', '唯有', '啊', '啊呀', '啊哈', '啊哟', '啐', '啥', '啦', '啪达', '啷当', '喀', '喂', '喏', '喔唷', '喽', '嗡', '嗡嗡', '嗬', '嗯', '嗳', '嘎', '嘎嘎', '嘎登', '嘘', '嘛', '嘻', '嘿', '嘿嘿', '四', '因', '因为', '因了', '因此', '因着', '因而', '固', '固然', '在', '在下', '在于', '地', '均', '坚决', '坚持', '基于', '基本', '基本上', '处在', '处处', '处理', '复杂', '多', '多么', '多亏', '多多', '多多少少', '多多益善', '多少', '多年前', '多年来', '多数', '多次', '够瞧的', '大', '大不了', '大举', '大事', '大体', '大体上', '大凡', '大力', '大多', '大多数', '大大', '大家', '大张旗鼓', '大批', '大抵', '大概', '大略', '大约', '大致', '大都', '大量', '大面儿上', '失去', '奇', '奈', '奋勇', '她', '她们', '她是', '她的', '好', '好在', '好的', '好象', '如', '如上', '如上所述', '如下', '如今', '如何', '如其', '如前所述', '如同', '如常', '如是', '如期', '如果', '如次', '如此', '如此等等', '如若', '始而', '姑且', '存在', '存心', '孰料', '孰知', '宁', '宁可', '宁愿', '宁肯', '它', '它们', '它们的', '它是', '它的', '安全', '完全', '完成', '定', '实现', '实际', '宣布', '容易', '密切', '对', '对于', '对应', '对待', '对方', '对比', '将', '将才', '将要', '将近', '小', '少数', '尔', '尔后', '尔尔', '尔等', '尚且', '尤其', '就', '就地', '就是', '就是了', '就是说', '就此', '就算', '就要', '尽', '尽可能', '尽如人意', '尽心尽力', '尽心竭力', '尽快', '尽早', '尽然', '尽管', '尽管如此', '尽量', '局外', '居然', '届时', '属于', '屡', '屡屡', '屡次', '屡次三番', '岂', '岂但', '岂止', '岂非', '川流不息', '左右', '巨大', '巩固', '差一点', '差不多', '己', '已', '已矣', '已经', '巴', '巴巴', '带', '帮助', '常', '常常', '常言说', '常言说得好', '常言道', '平素', '年复一年', '并', '并不', '并不是', '并且', '并排', '并无', '并没', '并没有', '并肩', '并非', '广大', '广泛', '应当', '应用', '应该', '庶乎', '庶几', '开外', '开始', '开展', '引起', '弗', '弹指之间', '强烈', '强调', '归', '归根到底', '归根结底', '归齐', '当', '当下', '当中', '当儿', '当前', '当即', '当口儿', '当地', '当场', '当头', '当庭', '当时', '当然', '当真', '当着', '形成', '彻夜', '彻底', '彼', '彼时', '彼此', '往', '往往', '待', '待到', '很', '很多', '很少', '後来', '後面', '得', '得了', '得出', '得到', '得天独厚', '得起', '心里', '必', '必定', '必将', '必然', '必要', '必须', '快', '快要', '忽地', '忽然', '怎', '怎么', '怎么办', '怎么样', '怎奈', '怎样', '怎麽', '怕', '急匆匆', '怪', '怪不得', '总之', '总是', '总的来看', '总的来说', '总的说来', '总结', '总而言之', '恍然', '恐怕', '恰似', '恰好', '恰如', '恰巧', '恰恰', '恰恰相反', '恰逢', '您', '您们', '您是', '惟其', '惯常', '意思', '愤然', '愿意', '慢说', '成为', '成年', '成年累月', '成心', '我', '我们', '我是', '我的', '或', '或则', '或多或少', '或是', '或曰', '或者', '或许', '战斗', '截然', '截至', '所', '所以', '所在', '所幸', '所有', '所谓', '才', '才能', '扑通', '打', '打从', '打开天窗说亮话', '扩大', '把', '抑或', '抽冷子', '拦腰', '拿', '按', '按时', '按期', '按照', '按理', '按说', '挨个', '挨家挨户', '挨次', '挨着', '挨门挨户', '挨门逐户', '换句话说', '换言之', '据', '据实', '据悉', '据我所知', '据此', '据称', '据说', '掌握', '接下来', '接着', '接著', '接连不断', '放量', '故', '故意', '故此', '故而', '敞开儿', '敢', '敢于', '敢情', '数/', '整个', '断然', '方', '方便', '方才', '方能', '方面', '旁人', '无', '无宁', '无法', '无论', '既', '既...又', '既往', '既是', '既然', '日复一日', '日渐', '日益', '日臻', '日见', '时候', '昂然', '明显', '明确', '是', '是不是', '是以', '是否', '是的', '显然', '显著', '普通', '普遍', '暗中', '暗地里', '暗自', '更', '更为', '更加', '更进一步', '曾', '曾经', '替', '替代', '最', '最后', '最大', '最好', '最後', '最近', '最高', '有', '有些', '有关', '有利', '有力', '有及', '有所', '有效', '有时', '有点', '有的', '有的是', '有着', '有著', '望', '朝', '朝着', '末##末', '本', '本人', '本地', '本着', '本身', '权时', '来', '来不及', '来得及', '来看', '来着', '来自', '来讲', '来说', '极', '极为', '极了', '极其', '极力', '极大', '极度', '极端', '构成', '果然', '果真', '某', '某个', '某些', '某某', '根据', '根本', '格外', '梆', '概', '次第', '欢迎', '欤', '正值', '正在', '正如', '正巧', '正常', '正是', '此', '此中', '此后', '此地', '此处', '此外', '此时', '此次', '此间', '殆', '毋宁', '每', '每个', '每天', '每年', '每当', '每时每刻', '每每', '每逢', '比', '比及', '比如', '比如说', '比方', '比照', '比起', '比较', '毕竟', '毫不', '毫无', '毫无例外', '毫无保留地', '汝', '沙沙', '没', '没奈何', '没有', '沿', '沿着', '注意', '活', '深入', '清楚', '满', '满足', '漫说', '焉', '然', '然则', '然后', '然後', '然而', '照', '照着', '牢牢', '特别是', '特殊', '特点', '犹且', '犹自', '独', '独自', '猛然', '猛然间', '率尔', '率然', '现代', '现在', '理应', '理当', '理该', '瑟瑟', '甚且', '甚么', '甚或', '甚而', '甚至', '甚至于', '用', '用来', '甫', '甭', '由', '由于', '由是', '由此', '由此可见', '略', '略为', '略加', '略微', '白', '白白', '的', '的确', '的话', '皆可', '目前', '直到', '直接', '相似', '相信', '相反', '相同', '相对', '相对而言', '相应', '相当', '相等', '省得', '看', '看上去', '看出', '看到', '看来', '看样子', '看看', '看见', '看起来', '真是', '真正', '眨眼', '着', '着呢', '矣', '矣乎', '矣哉', '知道', '砰', '确定', '碰巧', '社会主义', '离', '种', '积极', '移动', '究竟', '穷年累月', '突出', '突然', '窃', '立', '立刻', '立即', '立地', '立时', '立马', '竟', '竟然', '竟而', '第', '第二', '等', '等到', '等等', '策略地', '简直', '简而言之', '简言之', '管', '类如', '粗', '精光', '紧接着', '累年', '累次', '纯', '纯粹', '纵', '纵令', '纵使', '纵然', '练习', '组成', '经', '经常', '经过', '结合', '结果', '给', '绝', '绝不', '绝对', '绝非', '绝顶', '继之', '继后', '继续', '继而', '维持', '综上所述', '缕缕', '罢了', '老', '老大', '老是', '老老实实', '考虑', '者', '而', '而且', '而况', '而又', '而后', '而外', '而已', '而是', '而言', '而论', '联系', '联袂', '背地里', '背靠背', '能', '能否', '能够', '腾', '自', '自个儿', '自从', '自各儿', '自后', '自家', '自己', '自打', '自身', '臭', '至', '至于', '至今', '至若', '致', '般的', '良好', '若', '若夫', '若是', '若果', '若非', '范围', '莫', '莫不', '莫不然', '莫如', '莫若', '莫非', '获得', '藉以', '虽', '虽则', '虽然', '虽说', '蛮', '行为', '行动', '表明', '表示', '被', '要', '要不', '要不是', '要不然', '要么', '要是', '要求', '见', '规定', '觉得', '譬喻', '譬如', '认为', '认真', '认识', '让', '许多', '论', '论说', '设使', '设或', '设若', '诚如', '诚然', '话说', '该', '该当', '说明', '说来', '说说', '请勿', '诸', '诸位', '诸如', '谁', '谁人', '谁料', '谁知', '谨', '豁然', '贼死', '赖以', '赶', '赶快', '赶早不赶晚', '起', '起先', '起初', '起头', '起来', '起见', '起首', '趁', '趁便', '趁势', '趁早', '趁机', '趁热', '趁着', '越是', '距', '跟', '路经', '转动', '转变', '转贴', '轰然', '较', '较为', '较之', '较比', '边', '达到', '达旦', '迄', '迅速', '过', '过于', '过去', '过来', '运用', '近', '近几年来', '近年来', '近来', '还', '还是', '还有', '还要', '这', '这一来', '这个', '这么', '这么些', '这么样', '这么点儿', '这些', '这会儿', '这儿', '这就是说', '这时', '这样', '这次', '这点', '这种', '这般', '这边', '这里', '这麽', '进入', '进去', '进来', '进步', '进而', '进行', '连', '连同', '连声', '连日', '连日来', '连袂', '连连', '迟早', '迫于', '适应', '适当', '适用', '逐步', '逐渐', '通常', '通过', '造成', '逢', '遇到', '遭到', '遵循', '遵照', '避免', '那', '那个', '那么', '那么些', '那么样', '那些', '那会儿', '那儿', '那时', '那末', '那样', '那般', '那边', '那里', '那麽', '部分', '都', '鄙人', '采取', '里面', '重大', '重新', '重要', '鉴于', '针对', '长期以来', '长此下去', '长线', '长话短说', '问题', '间或', '防止', '阿', '附近', '陈年', '限制', '陡然', '除', '除了', '除却', '除去', '除外', '除开', '除此', '除此之外', '除此以外', '除此而外', '除非', '随', '随后', '随时', '随着', '随著', '隔夜', '隔日', '难得', '难怪', '难说', '难道', '难道说', '集中', '零', '需要', '非但', '非常', '非徒', '非得', '非特', '非独', '靠', '顶多', '顷', '顷刻', '顷刻之间', '顷刻间', '顺', '顺着', '顿时', '颇', '风雨无阻', '饱', '首先', '马上', '高低', '高兴', '默然', '默默地', '齐', '1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '']\n"
     ]
    }
   ],
   "source": [
    "with open('stopwords.txt','r', encoding='GB18030')as s:\n",
    "    stopwords = s.read().splitlines()\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [他家, 面, 嚼, 劲, 牛肉汤, 味道, 服务员, 服务, 特别, 服务员, 顾存芳, ...\n",
       "1       [鲜榨, 果汁, 不错, 水果, 新鲜, 口感, 小妹妹, 态度, 环境, 专家, 告诉, ...\n",
       "2       [老婆, 二人, 世界, 就定, 他家, 一间, 包房, 他家, 挺, 老婆, 点, 几个,...\n",
       "3       [开业, 那天, 环境, 一种, 温软, 感觉, 服务, 销售, 耐心, 老公, 介绍, 口...\n",
       "4       [好像, 说, 宁波, 菜系, 东西, 上菜, 速度, 比较慢, 服务, 不错, 赠送, 餐...\n",
       "                              ...                        \n",
       "9760    [苏浙, 汇吃, 新开, 家, 丰收, 日, 尝, 味道, 不错, 价格, 实惠, 贵, 包...\n",
       "9761    [世界末日, 到来, 21, 号, 钱, 用光, tmd, 谁造, 谣, 剩, 100, 钱...\n",
       "9762    [菜, 好吃, 剁, 椒, 鱼头, 强烈推荐, 建议, 老板, 稍微, 场地, 位置, 太,...\n",
       "9763      [公司, 楼下, 好吃, 麻辣烫, 老板, 河南人, 煮, 麻辣烫, 小姑娘, 长得, 不错]\n",
       "9764    [鸭, 王, 每桌, 点, 两道, 特价, 菜, 实惠, 菜, 味道, 周边, 朋友, 介绍...\n",
       "Name: text_nonstop, Length: 9765, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopwords]\n",
    "    return text\n",
    "data['text_nonstop'] = data['text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "data['text_nonstop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text_only = re.sub('[{}]+'.format(punctuation), \"\", text)\n",
    "    jieba_list = jieba.cut(text_only, cut_all=False)\n",
    "    tokens = ' '.join(jieba_list).split(' ')   \n",
    "    text_nonstop = [word for word in tokens if word not in stopwords]\n",
    "    return text_nonstop\n",
    "\n",
    "data['clean'] = data['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-119fbdd895be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtfidf_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_nonstop'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1650\u001b[0m         \"\"\"\n\u001b[0;32m   1651\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1652\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1653\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1654\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m-> 1058\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    968\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    350\u001b[0m                                                tokenize)\n\u001b[0;32m    351\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 352\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['text'])\n",
    "print(X_tfidf.shape)\n",
    "print(tfidf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
